# üß© NiFi ‚Äì H∆∞·ªõng d·∫´n Setup cho AURA

H∆∞·ªõng d·∫´n n√†y gi√∫p b·∫°n (v√† b·∫°n b√®) c√†i v√† c·∫•u h√¨nh **Apache NiFi** ƒë·ªÉ l√†m vi·ªác v·ªõi h·ªá th·ªëng AURA theo c√°ch **th·ªß c√¥ng, t·ª´ng b∆∞·ªõc m·ªôt**.

---

## 1. T·ªïng quan

- **M·ª•c ƒë√≠ch NiFi trong AURA**
  - ƒê·ªçc d·ªØ li·ªáu t·ª´ PostgreSQL (b·∫£ng `users`, `analysis_results`, ‚Ä¶).
  - Xu·∫•t b√°o c√°o ƒë·ªãnh k·ª≥ ra file (CSV, JSON,‚Ä¶).
  - ƒê·ªìng b·ªô d·ªØ li·ªáu real-time qua webhook + RabbitMQ.
  - T√≠nh to√°n analytics t·ªïng h·ª£p.
- **M√¥i tr∆∞·ªùng ch·∫°y**: NiFi ch·∫°y b·∫±ng Docker, ƒë√£ ƒë∆∞·ª£c khai b√°o trong `docker-compose.yml`.
- **Th√¥ng tin truy c·∫≠p m·∫∑c ƒë·ªãnh**:
  - URL: `https://localhost:8443/nifi`
  - Username: `admin`
  - Password: `aura_nifi_2024`

> ‚ö†Ô∏è Khi truy c·∫≠p l·∫ßn ƒë·∫ßu, tr√¨nh duy·ªát s·∫Ω b√°o l·ªói SSL t·ª± k√Ω. Ch·ªçn **‚ÄúAdvanced‚Äù ‚Üí ‚ÄúProceed to localhost (unsafe)‚Äù** ƒë·ªÉ ti·∫øp t·ª•c (ch·ªâ d√πng trong m√¥i tr∆∞·ªùng dev/local).

---

## 2. Kh·ªüi ƒë·ªông NiFi c√πng h·ªá th·ªëng

T·ª´ th∆∞ m·ª•c g·ªëc c·ªßa d·ª± √°n:

```bash
cd AURA-Retinal-Screening-System
docker-compose up -d
```

ƒê·ª£i v√†i ph√∫t cho t·∫•t c·∫£ container (bao g·ªìm `aura-nifi`) kh·ªüi ƒë·ªông.

Ki·ªÉm tra nhanh:

```bash
docker-compose ps nifi
```

N·∫øu tr·∫°ng th√°i l√† `Up` ‚Üí NiFi ƒë√£ ch·∫°y.

Sau ƒë√≥ m·ªü tr√¨nh duy·ªát t·ªõi: `https://localhost:8443/nifi` v√† ƒëƒÉng nh·∫≠p b·∫±ng `admin / aura_nifi_2024`.

---

## 3. Th√™m PostgreSQL JDBC Driver cho NiFi

NiFi c·∫ßn JDBC driver ƒë·ªÉ k·∫øt n·ªëi PostgreSQL.

1. M·ªü PowerShell t·∫°i th∆∞ m·ª•c d·ª± √°n:

   ```powershell
   cd D:\FIle_Hoc_Tap\XDPMHDT\AURA-Retinal-Screening-System
   ```

2. T·∫£i JDBC driver v√†o container NiFi:

   ```powershell
   docker-compose exec nifi wget -P /opt/nifi/nifi-current/lib https://jdbc.postgresql.org/download/postgresql-42.7.0.jar
   ```

3. Restart NiFi ƒë·ªÉ n·∫°p driver:

   ```powershell
   docker-compose restart nifi
   ```

4. Ki·ªÉm tra file ƒë√£ c√≥ trong container:

   ```powershell
   docker-compose exec nifi ls -la /opt/nifi/nifi-current/lib/postgresql-42.7.0.jar
   ```

---

## 4. T·∫°o Process Group ch√≠nh cho AURA

1. ƒêƒÉng nh·∫≠p NiFi UI: `https://localhost:8443/nifi`.
2. ·ªû canvas ch√≠nh, **click chu·ªôt ph·∫£i** ‚Üí **Create Process Group**.
3. ƒê·∫∑t t√™n: `AURA Flows`.
4. **Double-click** v√†o `AURA Flows` ƒë·ªÉ v√†o b√™n trong (t·∫•t c·∫£ flow s·∫Ω ƒë∆∞·ª£c t·∫°o trong group n√†y).

---

## 5. T·∫°o Controller Service k·∫øt n·ªëi PostgreSQL

1. Trong `AURA Flows`, click chu·ªôt ph·∫£i v√†o n·ªÅn canvas ‚Üí **Configure**.
2. Ch·ªçn tab **Controller Services**.
3. Click n√∫t **+** ‚Üí t√¨m `DBCPConnectionPool` ‚Üí **Add**.
4. Double-click v√†o service v·ª´a t·∫°o.
5. Tab **SETTINGS**:
   - Name: `AURA PostgreSQL Connection Pool`.
6. Tab **PROPERTIES**:

   | Property                    | Gi√° tr·ªã                                            |
   | --------------------------- | -------------------------------------------------- |
   | Database Connection URL     | `jdbc:postgresql://postgres:5432/aura_db`          |
   | Database Driver Class Name  | `org.postgresql.Driver`                            |
   | Database Driver Location(s) | `/opt/nifi/nifi-current/lib/postgresql-42.7.0.jar` |
   | Database User               | `aura_user`                                        |
   | Password                    | `aura_password_2024`                               |
   | Max Wait Time               | `30 seconds`                                       |
   | Max Total Connections       | `10`                                               |
   | Validation Query            | `SELECT 1`                                         |

7. B·∫•m **Apply**.
8. Trong danh s√°ch Controller Services, b·∫•m bi·ªÉu t∆∞·ª£ng **play** m√†u xanh ƒë·ªÉ **Enable** service.

Khi tr·∫°ng th√°i l√† **Enabled** ‚Üí NiFi ƒë√£ k·∫øt n·ªëi ƒë∆∞·ª£c PostgreSQL.

---

## 6. Flow m·∫´u 1: ƒê·ªçc d·ªØ li·ªáu t·ª´ b·∫£ng `users` v√† l∆∞u ra file

Flow n√†y d√πng ƒë·ªÉ test nhanh k·∫øt n·ªëi DB + file h·ªá th·ªëng c·ªßa NiFi.

### 6.1. T·∫°o Process Group

1. Trong `AURA Flows`, click chu·ªôt ph·∫£i ‚Üí **Create Process Group**.
2. ƒê·∫∑t t√™n: `Read Database Flow`.
3. Double-click ƒë·ªÉ v√†o b√™n trong.

### 6.2. Processor `QueryDatabaseTable`

1. B·∫•m icon **Add Processor** tr√™n toolbar.
2. T√¨m `QueryDatabaseTable` ‚Üí **Add**.
3. Double-click v√†o processor.
4. Tab **PROPERTIES**:
   - **Database Connection Pooling Service**: ch·ªçn `AURA PostgreSQL Connection Pool`.
   - **Table Name**: `users`.
   - **Columns to Return**: ƒë·ªÉ tr·ªëng (l·∫•y t·∫•t c·∫£).
5. Tab **SCHEDULING**:
   - **Run Schedule**: `5 min` (ho·∫∑c `30 sec` ƒë·ªÉ test).
6. B·∫•m **Apply**.

### 6.3. Processor `PutFile`

1. Th√™m processor m·ªõi: `PutFile` ‚Üí **Add**.
2. Double-click `PutFile`.
3. Tab **PROPERTIES**:
   - **Directory**: `/tmp/nifi-output/users`.
   - **Conflict Resolution Strategy**: `replace`.
   - **Create Missing Directories**: `true` (n·∫øu version c√≥ t√πy ch·ªçn n√†y).
4. Tab **Relationships**:
   - ƒê·∫£m b·∫£o `success` ƒë∆∞·ª£c **terminate** (n·∫øu kh√¥ng n·ªëi sang processor kh√°c).
5. B·∫•m **Apply**.

### 6.4. K·∫øt n·ªëi v√† ch·∫°y th·ª≠

1. K√©o chu·ªôt t·ª´ `QueryDatabaseTable` ‚Üí `PutFile` ‚Üí ch·ªçn relationship **success**.
2. Click chu·ªôt ph·∫£i t·ª´ng processor ‚Üí **Start** (b·∫Øt ƒë·∫ßu t·ª´ `QueryDatabaseTable`, r·ªìi t·ªõi `PutFile`).
3. Sau 30 gi√¢y‚Äì5 ph√∫t (tu·ª≥ Run Schedule), NiFi s·∫Ω t·∫°o file trong th∆∞ m·ª•c `/tmp/nifi-output/users` b√™n trong container NiFi.

ƒê·ªÉ xem file trong container:

```powershell
docker-compose exec nifi ls -la /tmp/nifi-output/users
```

N·∫øu th·∫•y file `.json`/`.csv` ƒë∆∞·ª£c t·∫°o ‚Üí NiFi ƒë√£ k·∫øt n·ªëi DB v√† ghi file th√†nh c√¥ng.

---

## 7. G·ª£i √Ω c√°c flow n√¢ng cao cho AURA

Sau khi l√†m xong Flow m·∫´u 1, b·∫°n c√≥ th·ªÉ t·ª± x√¢y d·ª±ng c√°c flow n√¢ng cao theo nhu c·∫ßu d·ª± √°n:

- **Flow Export B√°o c√°o ƒê·ªãnh k·ª≥**
  - `QueryDatabaseTable` ƒë·ªçc t·ª´ `analysis_results` v·ªõi ƒëi·ªÅu ki·ªán th·ªùi gian (`CreatedDate >= CURRENT_DATE - INTERVAL '1 day'`).
  - `UpdateAttribute` ƒë·∫∑t t√™n file (v√≠ d·ª• `analysis_report_YYYY-MM-DD.csv`).
  - `PutFile` ghi ra th∆∞ m·ª•c `/tmp/nifi-output/reports`.

- **Flow ƒê·ªìng b·ªô Real-time qua Webhook + RabbitMQ**
  - `ListenHTTP` nh·∫≠n JSON t·ª´ backend (base path `/webhook/analysis`).
  - `EvaluateJSONPath` t√°ch c√°c tr∆∞·ªùng `type`, `data`.
  - `RouteOnAttribute` route theo `event.type` (`analysis.completed`, `image.uploaded`, ‚Ä¶).
  - `PutRabbitMQ` g·ª≠i message sang RabbitMQ (exchange `analysis.exchange`, routing key `analysis.start`).

---

## 9. Flow Webhook + RabbitMQ Chi ti·∫øt - H∆∞·ªõng d·∫´n c·∫•u h√¨nh

### 9.1. C·∫•u h√¨nh RabbitMQ (T·∫°o Exchanges & Queues)

Tr∆∞·ªõc ti√™n, b·∫°n c·∫ßn t·∫°o c√°c exchanges v√† queues trong RabbitMQ.

1. M·ªü RabbitMQ Management UI: `http://localhost:15672`
   - Username: `aura_user`
   - Password: `aura_password_2024`

2. **T·∫°o Exchanges** - Click tab **Exchanges** ‚Üí **Add a new exchange**:

   | T√™n Exchange             | Type     | Durable | Auto-delete |
   | ------------------------ | -------- | ------- | ----------- |
   | `analysis.exchange`      | `topic`  | ‚úì       | ‚úó           |
   | `image.exchange`         | `topic`  | ‚úì       | ‚úó           |
   | `notifications.exchange` | `direct` | ‚úì       | ‚úó           |

3. **T·∫°o Queues** - Click tab **Queues and Streams** ‚Üí **Add a new queue**:

   | Queue Name                 | Durable | Auto-delete |
   | -------------------------- | ------- | ----------- |
   | `analysis.completed.queue` | ‚úì       | ‚úó           |
   | `analysis.failed.queue`    | ‚úì       | ‚úó           |
   | `image.uploaded.queue`     | ‚úì       | ‚úó           |
   | `notifications.queue`      | ‚úì       | ‚úó           |

4. **Binding Queues to Exchanges** - Trong tab **Exchanges**, click v√†o t·ª´ng exchange r·ªìi **Add binding**:

   **Cho `analysis.exchange`:**
   - To queue: `analysis.completed.queue` | Routing key: `analysis.completed`
   - To queue: `analysis.failed.queue` | Routing key: `analysis.failed`

   **Cho `image.exchange`:**
   - To queue: `image.uploaded.queue` | Routing key: `image.uploaded`

   **Cho `notifications.exchange`:**
   - To queue: `notifications.queue` | Routing key: `*`

### 9.2. C·∫•u h√¨nh NiFi Controller Service cho RabbitMQ

1. Trong `AURA Flows`, click chu·ªôt ph·∫£i v√†o n·ªÅn canvas ‚Üí **Configure**.
2. Ch·ªçn tab **Controller Services**.
3. Click n√∫t **+** ‚Üí t√¨m `StandardAmqpConnectionFactory` ‚Üí **Add**.
4. Double-click v√†o service v·ª´a t·∫°o.
5. Tab **SETTINGS**:
   - Name: `AURA RabbitMQ Connection`.
6. Tab **PROPERTIES**:

   | Property   | Gi√° tr·ªã                                             |
   | ---------- | --------------------------------------------------- |
   | Broker URI | `amqp://aura_user:aura_password_2024@rabbitmq:5672` |
   | Use SSL    | `false` (cho development)                           |

7. B·∫•m **Apply** ‚Üí Enable service (bi·ªÉu t∆∞·ª£ng play).

### 9.3. T·∫°o Process Group cho Webhook Flow

1. Trong `AURA Flows`, click chu·ªôt ph·∫£i ‚Üí **Create Process Group**.
2. ƒê·∫∑t t√™n: `Real-time Webhook Flow`.
3. Double-click ƒë·ªÉ v√†o b√™n trong.

### 9.4. Processor `ListenHTTP` (Nh·∫≠n webhook t·ª´ backend)

1. B·∫•m icon **Add Processor**.
2. T√¨m `ListenHTTP` ‚Üí **Add**.
3. Double-click v√†o processor.
4. Tab **PROPERTIES**:
   - **Listening Port**: `8080`
   - **Base Path**: `/webhook`
   - **HTTP Methods**: `POST`
   - **Max Data to Buffer (bytes)**: `1048576`

5. Tab **SCHEDULING**:
   - **Concurrent tasks**: `5`

6. B·∫•m **Apply**.

### 9.5. Processor `ConvertJSONToSQL` ho·∫∑c `EvaluateJSONPath`

1. Th√™m processor: `EvaluateJSONPath` ‚Üí **Add**.
2. Double-click v√†o processor.
3. Tab **PROPERTIES**:
   - Click n√∫t **+** ƒë·ªÉ th√™m c√°c JSON path properties:

   | Property Name | JSON Path            |
   | ------------- | -------------------- |
   | `event_type`  | `$.event_type`       |
   | `user_id`     | `$.data.user_id`     |
   | `analysis_id` | `$.data.analysis_id` |
   | `risk_score`  | `$.data.risk_score`  |
   | `timestamp`   | `$.timestamp`        |
   - **Destination**: `flowfile-attribute`

4. B·∫•m **Apply**.

### 9.6. Processor `RouteOnAttribute` (Route theo event type)

1. Th√™m processor: `RouteOnAttribute` ‚Üí **Add**.
2. Double-click v√†o processor.
3. Tab **PROPERTIES**:
   - Click n√∫t **+** ƒë·ªÉ th√™m routing rules:

   | Property Name        | Gi√° tr·ªã                                      |
   | -------------------- | -------------------------------------------- |
   | `analysis_completed` | `${event_type:equals('analysis.completed')}` |
   | `analysis_failed`    | `${event_type:equals('analysis.failed')}`    |
   | `image_uploaded`     | `${event_type:equals('image.uploaded')}`     |
   - B·ªè tr·ªëng **Routing Configuration** (ƒë·ªÉ m·∫∑c ƒë·ªãnh)

4. B·∫•m **Apply**.

### 9.7. Processor `PutRabbitMQ` (G·ª≠i message l√™n RabbitMQ)

B·∫°n c·∫ßn t·∫°o 3 processor `PutRabbitMQ` (m·ªôt cho m·ªói route).

**Cho route `analysis.completed`:**

1. Th√™m processor: `PutRabbitMQ` ‚Üí **Add**.
2. Double-click v√†o processor.
3. Tab **PROPERTIES**:
   - **AMQP Connection Factory**: ch·ªçn `AURA RabbitMQ Connection`.
   - **Exchange Name**: `analysis.exchange`
   - **Routing Key**: `analysis.completed`
   - **Message TTL**: `3600000` (1 gi·ªù)
   - **Delivery Mode**: `2` (Persistent)

4. Tab **RELATIONSHIPS**: Terminate `success` v√† `failure`.
5. B·∫•m **Apply**.

**T∆∞∆°ng t·ª±** cho `analysis_failed` (Routing Key: `analysis.failed`) v√† `image_uploaded` (Exchange: `image.exchange`, Routing Key: `image.uploaded`).

### 9.8. K·∫øt n·ªëi c√°c Processor

1. K√©o t·ª´ `ListenHTTP` ‚Üí `EvaluateJSONPath` ‚Üí ch·ªçn `success`.
2. K√©o t·ª´ `EvaluateJSONPath` ‚Üí `RouteOnAttribute` ‚Üí ch·ªçn `success`.
3. K√©o t·ª´ `RouteOnAttribute` ‚Üí `PutRabbitMQ` (analysis_completed) ‚Üí ch·ªçn `analysis_completed`.
4. K√©o t·ª´ `RouteOnAttribute` ‚Üí `PutRabbitMQ` (analysis_failed) ‚Üí ch·ªçn `analysis_failed`.
5. K√©o t·ª´ `RouteOnAttribute` ‚Üí `PutRabbitMQ` (image_uploaded) ‚Üí ch·ªçn `image_uploaded`.
6. Terminate c√°c unmatched relationship t·ª´ `RouteOnAttribute`.

### 9.9. Test Flow

1. Start t·∫•t c·∫£ processors.
2. G·ª≠i test webhook t·ª´ PowerShell:

   ```powershell
   $headers = @{"Content-Type" = "application/json"}
   $body = @{
       event_type = "analysis.completed"
       data = @{
           user_id = "user123"
           analysis_id = "analysis456"
           risk_score = 0.85
       }
       timestamp = Get-Date -Format "yyyy-MM-ddTHH:mm:ss"
   } | ConvertTo-Json

   Invoke-WebRequest -Uri "http://localhost:8080/webhook" `
       -Method POST `
       -Headers $headers `
       -Body $body
   ```

3. **Ki·ªÉm tra RabbitMQ**:
   - V√†o `http://localhost:15672` ‚Üí **Queues** ‚Üí Ki·ªÉm tra s·ªë message trong queue.
   - Click v√†o queue ‚Üí **Get messages** ƒë·ªÉ xem n·ªôi dung.

### 9.10. Troubleshooting

| V·∫•n ƒë·ªÅ                             | Gi·∫£i ph√°p                                                       |
| ---------------------------------- | --------------------------------------------------------------- |
| **ListenHTTP kh√¥ng nh·∫≠n request**  | Ki·ªÉm tra firewall/port 8080, base path ƒë√∫ng ch∆∞a.               |
| **PutRabbitMQ b√°o l·ªói connection** | Ki·ªÉm tra RabbitMQ ƒë√£ ch·∫°y: `docker-compose ps rabbitmq`.        |
| **Message kh√¥ng v√†o queue**        | Ki·ªÉm tra exchange & routing key ƒë√∫ng ch∆∞a (xem RabbitMQ UI).    |
| **EvaluateJSONPath b√°o l·ªói**       | Ki·ªÉm tra JSON structure t·ª´ webhook c√≥ kh·ªõp v·ªõi JSON path kh√¥ng. |

- **Flow Analytics**
  - `ExecuteSQL` ch·∫°y c√°c query t·ªïng h·ª£p (COUNT, AVG‚Ä¶) tr√™n `analysis_results`.
  - `PutFile` ho·∫∑c `PutDatabaseRecord` l∆∞u k·∫øt qu·∫£ t·ªïng h·ª£p.

---

## 8. Flow Analytics Chi ti·∫øt - H∆∞·ªõng d·∫´n c·∫•u h√¨nh

### 8.1. T·∫°o Process Group m·ªõi

1. Trong `AURA Flows`, click chu·ªôt ph·∫£i ‚Üí **Create Process Group**.
2. ƒê·∫∑t t√™n: `Analytics Flow`.
3. Double-click ƒë·ªÉ v√†o b√™n trong.

### 8.2. Processor `ExecuteSQL` (Ch·∫°y query t·ªïng h·ª£p)

1. B·∫•m icon **Add Processor** tr√™n toolbar.
2. T√¨m `ExecuteSQL` ‚Üí **Add**.
3. Double-click v√†o processor.
4. Tab **PROPERTIES**:
   - **Database Connection Pooling Service**: ch·ªçn `AURA PostgreSQL Connection Pool`.
   - **SQL select query**: Nh·∫≠p m·ªôt trong c√°c query d∆∞·ªõi ƒë√¢y:

   **V√≠ d·ª• 1: Th·ªëng k√™ t·ªïng quan Analysis**

   ```sql
   SELECT
       COUNT(*) as total_analysis,
       COUNT(DISTINCT userid) as total_users,
       ROUND(AVG(riskscore), 2) as avg_risk_score,
       MAX(riskscore) as max_risk_score,
       MIN(riskscore) as min_risk_score,
       MAX(createddate) as last_analysis_date
   FROM analysis_results
   WHERE isdeleted = false;
   ```

   **V√≠ d·ª• 2: Th·ªëng k√™ theo lo·∫°i b·ªánh**

   ```sql
   SELECT
       'Hypertension' as condition,
       COUNT(CASE WHEN hypertensionconcern = true THEN 1 END) as concern_count,
       COUNT(*) as total_count,
       ROUND(100.0 * COUNT(CASE WHEN hypertensionconcern = true THEN 1 END) / COUNT(*), 2) as percentage
   FROM analysis_results
   WHERE isdeleted = false
   UNION ALL
   SELECT
       'Diabetes' as condition,
       COUNT(CASE WHEN diabetes != 'None' THEN 1 END) as concern_count,
       COUNT(*) as total_count,
       ROUND(100.0 * COUNT(CASE WHEN diabetes != 'None' THEN 1 END) / COUNT(*), 2) as percentage
   FROM analysis_results
   WHERE isdeleted = false
   UNION ALL
   SELECT
       'Stroke Risk' as condition,
       COUNT(CASE WHEN strokeconcern > 0 THEN 1 END) as concern_count,
       COUNT(*) as total_count,
       ROUND(100.0 * COUNT(CASE WHEN strokeconcern > 0 THEN 1 END) / COUNT(*), 2) as percentage
   FROM analysis_results
   WHERE isdeleted = false;
   ```

   **V√≠ d·ª• 3: ƒê·ªô ch√≠nh x√°c v√† Risk Score trung b√¨nh**

   ```sql
   SELECT
       COUNT(*) as total_records,
       ROUND(AVG(riskscore), 4) as avg_risk_score,
       ROUND(STDDEV(riskscore), 4) as stddev_risk_score,
       MAX(riskscore) as max_risk_score,
       MIN(riskscore) as min_risk_score
   FROM analysis_results
   WHERE isdeleted = false;
   ```

5. Tab **SCHEDULING**:
   - **Run Schedule**: `1 day` (ho·∫∑c `30 sec` ƒë·ªÉ test).

6. B·∫•m **Apply**.

### 8.3. Processor `UpdateAttribute` (ƒê·∫∑t t√™n file)

1. Th√™m processor m·ªõi: `UpdateAttribute` ‚Üí **Add**.
2. Double-click v√†o processor.
3. Tab **PROPERTIES**:
   - Click n√∫t **+** ƒë·ªÉ th√™m property.
   - **T√™n property**: `analytics_filename`
   - **Gi√° tr·ªã**: `analytics_report_${now():format('yyyy-MM-dd_HHmmss')}.json`

4. B·∫•m **Apply**.

### 8.4. Processor `PutFile` (L∆∞u k·∫øt qu·∫£ ra file)

1. Th√™m processor m·ªõi: `PutFile` ‚Üí **Add**.
2. Double-click v√†o processor.
3. Tab **PROPERTIES**:
   - **Directory**: `/tmp/nifi-output/analytics`.
   - **Filename**: `${analytics_filename}`.
   - **Conflict Resolution Strategy**: `replace`.
   - **Create Missing Directories**: `true`.

4. B·∫•m **Apply**.

### 8.5. K·∫øt n·ªëi c√°c Processor

1. K√©o chu·ªôt t·ª´ `ExecuteSQL` ‚Üí `UpdateAttribute` ‚Üí ch·ªçn relationship **success**.
2. K√©o chu·ªôt t·ª´ `UpdateAttribute` ‚Üí `PutFile` ‚Üí ch·ªçn relationship **success**.
3. Click chu·ªôt ph·∫£i v√†o `PutFile` ‚Üí **Configure** ‚Üí Tab **Relationships** ‚Üí Terminate `success`.

### 8.6. Ch·∫°y v√† Test Flow

1. Click chu·ªôt ph·∫£i v√†o `ExecuteSQL` ‚Üí **Start**.
2. Click chu·ªôt ph·∫£i v√†o `UpdateAttribute` ‚Üí **Start**.
3. Click chu·ªôt ph·∫£i v√†o `PutFile` ‚Üí **Start**.

4. Ch·∫°y ngay b·∫±ng c√°ch double-click v√†o `ExecuteSQL` ‚Üí b·∫•m n√∫t **EXECUTE**.

5. **Ki·ªÉm tra k·∫øt qu·∫£**:
   ```powershell
   docker-compose exec nifi ls -la /tmp/nifi-output/analytics
   docker-compose exec nifi cat /tmp/nifi-output/analytics/analytics_report_*.json
   ```

> N·∫øu b·∫°n mu·ªën chia s·∫ª chi ti·∫øt h∆°n cho b·∫°n b√®, c√≥ th·ªÉ t·∫°o th√™m c√°c file nh∆∞ `FLOW_EXPORT_REPORT.md`, `FLOW_REALTIME_SYNC.md`,‚Ä¶ trong c√πng th∆∞ m·ª•c `nifi/` v√† m√¥ t·∫£ t·ª´ng processor gi·ªëng phong c√°ch h∆∞·ªõng d·∫´n ·ªü tr√™n.

---

## 8. Tips & Troubleshooting nhanh

- Processor c√≥ **d·∫•u ch·∫•m than v√†ng** (`Invalid`):
  - M·ªü c·∫•u h√¨nh ‚Üí xem tab **Settings/Properties/Relationships** ƒë·ªÉ xem message c·ª• th·ªÉ.
  - Quan h·ªá (`relationship`) n√†o kh√¥ng n·ªëi ƒëi ƒë√¢u th√¨ c·∫ßn **terminate**.
- Kh√¥ng th·∫•y d·ªØ li·ªáu t·ª´ DB:
  - Ki·ªÉm tra l·∫°i Table Name, c·ªôt trong `Where Clause` c√≥ t·ªìn t·∫°i kh√¥ng (v√≠ d·ª• d√πng `CreatedDate` thay v√¨ `created_at`).
  - D√πng pgAdmin ch·∫°y th·ª≠ ch√≠nh c√¢u SQL xem c√≥ k·∫øt qu·∫£ kh√¥ng.
- `PutFile` b√°o l·ªói th∆∞ m·ª•c:
  - ƒê·∫£m b·∫£o ƒë∆∞·ªùng d·∫´n trong container t·ªìn t·∫°i (ho·∫∑c b·∫≠t `Create Missing Directories` n·∫øu c√≥).
  - Test b·∫±ng c√¢u l·ªánh:
    ```powershell
    docker-compose exec nifi mkdir -p /tmp/nifi-output/test
    ```

---

## 9. D√†nh cho ng∆∞·ªùi m·ªõi clone d·ª± √°n

1. L√†m theo `README.md` ·ªü th∆∞ m·ª•c g·ªëc ƒë·ªÉ ch·∫°y to√†n b·ªô h·ªá th·ªëng b·∫±ng Docker Compose.
2. ƒê·∫£m b·∫£o truy c·∫≠p ƒë∆∞·ª£c:
   - `http://localhost:5000/swagger`
   - `http://localhost:5050` (pgAdmin)
   - `https://localhost:8443/nifi` (NiFi)
3. M·ªü file n√†y (`nifi/README.md`) v√† th·ª±c hi·ªán l·∫ßn l∆∞·ª£t:
   - Th√™m JDBC driver.
   - T·∫°o Controller Service PostgreSQL.
   - T·∫°o Flow `Read Database Flow` ƒë·ªÉ test.
4. Sau khi test OK, tu·ª≥ ch·ªânh v√† t·∫°o th√™m c√°c flow ph√π h·ª£p nhu c·∫ßu (export b√°o c√°o, realtime sync, analytics, ‚Ä¶).
